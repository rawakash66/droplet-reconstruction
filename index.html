<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Droplets are 3D reconstructed from freely captured non-orthogonal images.">
  <meta name="keywords" content="Transparent reconstruction, shape-from-silhouette, Liquid contact angle">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Computer vision-based on-site estimation of contact angle from 3D reconstruction of droplets</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Computer vision-based on-site estimation of contact angle from 3D reconstruction of droplets</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/rawakash/">Akash Kumar</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://chandraprakashster.wixsite.com/chan/">Dr. C. Chandraprakash</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Indian Institute of Technology Kanpur</span>
          </div>
        
          <div class="is-size-5 publisher">
            <span class="publisher-block"><b>IEEE Transactions on Intrumentation and Measurement</b></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/rawakash66/transparent-drop-reconstruction"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
    
<section class="section">
  <div class="container is-max-desktop">
      <!-- Reconstructed droplet screenshot. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-image">
          <img src="./static/images/reconstructed%20droplet.png"
                 class="droplet-image"
                 alt="Reconstructed droplet image."/>
          <p><b>The droplet is inclined on the substrate at an tilt angle of 30&deg;</b></p>
        </div>
      </div>
    </div>
    <!--/ Reconstructed droplet screenshot. -->
 </div>
</section>



<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-fullbody">
          <img src="./static/images/P_fig12-13_fmap.png"
                 class="droplet-image"
                 alt="Reconstructed droplet image."/>
        </div>
        <div class="item item-chair-tp">
          <img src="./static/images/P_fig6_lensDist.png"
                 class="droplet-image"
                 alt="Reconstructed droplet image."/>
        </div>
        <div class="item item-shiba">
          <img src="./static/images/P_fig5_reprojError.png"
                 class="droplet-image"
                 alt="Reconstructed droplet image."/>
        </div>
        <div class="item item-steve">
          <img src="./static/images/methodology.png"
                 class="droplet-image"
                 alt="Reconstructed droplet image."/>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current methods to measure the contact angle require orthogonal imaging of the droplet and substrate. We have developed a novel computer vision-based technique to reconstruct the surface of the 3D transparent microdroplet from non-orthogonal images and determine the contact angle using custom-made equipment comprising a smartphone camera and macro lens.
          </p>
          <p>
            After estimating the intrinsic and extrinsic camera parameters using a printed pattern, the EfficientNet-B4 model of U-Net CNN architecture was used to extract silhouettes of droplets from images using semantic segmentation. Finally, the shape-from-silhouette method was employed involving a space carving algorithm to estimate the visual hull containing the droplet volume. Comparison with measurements from a state-of-the-art goniometer of static and dynamic contact angles on various substrates using a standard goniometer revealed an average error of 4%. Our method, using non-orthogonal images, was found to be successful for the on-site measurement of static and dynamic contact angles, as well as 3D reconstruction of the transparent droplets.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Setup Images. -->
      <div class="column">
        <div class="content">
          <h3 class="title is-4">Experimental Setup</h3>
          <p>
            A setup was designed to hold and tilt the substrate. It comprises (b,c) base disk, (b,d) two supporting stands, (a,f) four connector joins, and (a,e) stage. All of these were fabricated using polylactic acid on a 3D printer (Ender 3, Creality, Shenzhen, China).
          </p>
          <img src="./static/images/P_fig1_setup.png"
                 class="setup-image"
                 alt="Experimental setup image."/>
        </div>
      </div>
      <!--/ Setup images. -->

      <!-- Data Acquisition. -->
      <div class="column">
        <h3 class="title is-4">Data Acquisition</h3>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We used the (a) Motorola Edge 20 Pro mobile phone along with (b) SIGNI Pro 15&times; macro lens for data acquisition. The focal length of the lens varies from 25 to 55 mm. The data acquisition system provides (1836 &times; 3264) 6 MP resolution for the macro images of small (30 &micro;l) droplets
            </p>
            <img src="./static/images/P_fig2_daq.png"
                 class="data-acquisition-image"
                 alt="DA image."/>
          </div>

        </div>
      </div>
    </div>
    <!--/ Data Acquisition. -->
    
    <!-- Calibration. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Calibration and Pose Estimation</h3>
        <div class="content has-text-justified">
          <p>
             An asymmetrical pattern of circles was printed on a photo paper of size 10 &times; 7.3 mm<sup>2</sup> for camera calibration and pose estimation purposes. The intrinsic parameters, i.e. intrinsic camera matrix and lens distortion coefficients, were estimated based on the Zhang and Brown-Conrady models, respectively. Below is the (a) pattern image and (b) tracked points
          </p>
          <img src="./static/images/P_fig4_camCalib.png"
                 class="val-pred-image"
                 alt="segmentation image."/>
        </div>
      </div>
    </div>
    <!--/ Calibration. -->

    <!-- Image Segmentation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Transparent Droplet Segmentation</h3>
        <div class="content has-text-justified">
          <p>
             We used the U-Net CNN architecture for segmentation due to its robust performance in medical imaging and microscopic image segmentation of transparent irregular-shaped cells. For our purpose, the backbone of the model was taken as the EfficientNet-B4 architecture with pre-trained weights from the imagenet dataset. Below image is the (a) acquired droplet image, (b) ground truth, and (c) prediction from trained model.
          </p>
          <img src="./static/images/P_fig10_valPred.png"
                 class="val-pred-image"
                 alt="segmentation image."/>
        </div>
      </div>
    </div>
    <!--/ Segmentation. -->
    
    <!-- Space Carving. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h3 class="title is-4">Shape-from-silhouette</h3>
        <div class="content has-text-justified">
          <p>
             We used the space carving algorithm of shape-from-silhouette method. It includes the projection of all 3D points and the generation of the occupancy vector. The occupancy vector stores the visibility information of 3D points across all views. With appropriately chosen threshold we can generate the visual hull of the droplet that can be later used for angle measurement.  
          </p>
          <img src="./static/images/P_fig15_spaceCarving.png"
                 class="val-pred-image"
                 alt="segmentation image."/>
        </div>
      </div>
    </div>
    <!--/ Space Carving. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h3 class="title">BibTeX</h3>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Source code for the webpage borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
